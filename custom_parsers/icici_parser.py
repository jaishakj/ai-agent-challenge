"""
ICICI Bank Statement Parser
Custom parser for ICICI bank PDF statements
Auto-generated by parser_generator.py
"""

import pandas as pd
import re
import logging
from typing import List, Dict, Any, Optional
import pdfplumber
from datetime import datetime
import numpy as np

logger = logging.getLogger(__name__)


class IciciParser:
    """Custom parser for ICICI bank statements"""

    def __init__(self):
        self.bank_name = "ICICI"
        self.required_columns = ["Date", "Description", "Debit", "Credit", "Balance"]

        # ICICI-specific patterns
        self.date_patterns = [
            r"\d{2}/\d{2}/\d{4}",
            r"\d{2}-\d{2}-\d{4}",
            r"\d{2} \w{3} \d{4}",
        ]

        self.amount_patterns = [
            r"[\d,]+\.\d{2}",
            r"\d{1,3}(?:,\d{3})*\.\d{2}",
        ]

        # ICICI transaction keywords
        self.transaction_keywords = [
            "neft",
            "imps",
            "upi",
            "atm",
            "pos",
            "ach",
            "ecs",
            "salary",
            "transfer",
            "deposit",
            "withdrawal",
            "payment",
            "interest",
            "charges",
            "fee",
            "cheque",
            "online",
            "mobile",
        ]

        # Common ICICI table headers
        self.expected_headers = [
            ["Date", "Description", "Debit", "Credit", "Balance"],
            [
                "Transaction Date",
                "Description",
                "Debit Amount",
                "Credit Amount",
                "Balance",
            ],
            ["Date", "Particulars", "Debit", "Credit", "Balance"],
            ["Txn Date", "Description", "Dr Amount", "Cr Amount", "Balance"],
        ]

    def parse(self, pdf_path: str) -> pd.DataFrame:
        """Parse ICICI PDF statement and return DataFrame"""
        try:
            logger.info(f"Starting to parse ICICI statement: {pdf_path}")

            # Try table extraction first
            df = self._extract_from_tables(pdf_path)

            # If table extraction fails, try regex patterns
            if df.empty:
                logger.info("Table extraction failed, trying regex patterns")
                df = self._extract_with_regex(pdf_path)

            # If both fail, try line-by-line parsing
            if df.empty:
                logger.info("Regex extraction failed, trying line-by-line parsing")
                df = self._extract_line_by_line(pdf_path)

            # Final validation and cleaning
            df = self._validate_and_clean(df)

            logger.info(f"Successfully parsed {len(df)} transactions")
            return df

        except Exception as e:
            logger.error(f"Error parsing ICICI PDF: {e}")
            return pd.DataFrame(columns=self.required_columns)

    # ------------------------------------------------------------
    # Extraction methods
    # ------------------------------------------------------------
    def _extract_from_tables(self, pdf_path: str) -> pd.DataFrame:
        all_transactions = []

        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    logger.debug(f"Processing page {page_num + 1}")
                    tables = page.extract_tables()

                    for table_idx, table in enumerate(tables):
                        if table and len(table) > 1:
                            if self._is_transaction_table(table):
                                logger.debug(
                                    f"Found transaction table on page {page_num + 1}"
                                )
                                transactions = self._parse_transaction_table(table)
                                all_transactions.extend(transactions)

            if all_transactions:
                df = pd.DataFrame(all_transactions)
                return self._standardize_columns(df)

        except Exception as e:
            logger.error(f"Error in table extraction: {e}")

        return pd.DataFrame()

    def _extract_with_regex(self, pdf_path: str) -> pd.DataFrame:
        transactions = []

        try:
            full_text = self._extract_text(pdf_path)
            patterns = [
                r"(\d{2}/\d{2}/\d{4})\s+(.+?)\s+([\d,]*\.?\d{2}?)\s+([\d,]*\.?\d{2}?)\s+([\d,]+\.\d{2})",
                r"(\d{2}-\d{2}-\d{4})\s+(.+?)\s+(?:Dr|Cr)?\s*([\d,]+\.\d{2})\s+([\d,]+\.\d{2})",
                r"(\d{2}/\d{2}/\d{4})\s+(.{10,100}?)\s+([\d,]+\.\d{2})",
            ]

            for pattern in patterns:
                matches = re.findall(pattern, full_text, re.MULTILINE)
                logger.debug(f"Pattern '{pattern[:50]}...' found {len(matches)} matches")

                if matches:
                    for match in matches:
                        transaction = self._parse_regex_match(match, pattern)
                        if transaction and self._is_valid_transaction(transaction):
                            transactions.append(transaction)

                    if len(transactions) > 5:
                        break

            if transactions:
                df = pd.DataFrame(transactions)
                return self._standardize_columns(df)

        except Exception as e:
            logger.error(f"Error in regex extraction: {e}")

        return pd.DataFrame()

    def _extract_line_by_line(self, pdf_path: str) -> pd.DataFrame:
        transactions = []

        try:
            text = self._extract_text(pdf_path)
            lines = text.split("\n")

            for line in lines:
                line = line.strip()
                if self._looks_like_transaction_line(line):
                    transaction = self._parse_transaction_line(line)
                    if transaction and self._is_valid_transaction(transaction):
                        transactions.append(transaction)

            if transactions:
                df = pd.DataFrame(transactions)
                return self._standardize_columns(df)

        except Exception as e:
            logger.error(f"Error in line-by-line extraction: {e}")

        return pd.DataFrame()

    def _extract_text(self, pdf_path: str) -> str:
        text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
        except Exception as e:
            logger.error(f"Error extracting text from PDF: {e}")
        return text

    # ------------------------------------------------------------
    # Validation, mapping & cleaning
    # ------------------------------------------------------------
    def _standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """Standardize column names and ensure all required columns exist"""
        if df.empty:
            return pd.DataFrame(columns=self.required_columns)

        column_mapping = {
            "transaction date": "Date",
            "txn date": "Date",
            "date": "Date",
            "particulars": "Description",
            "description": "Description",
            "details": "Description",
            "narration": "Description",
            "debit amount": "Debit",
            "dr amount": "Debit",
            "debit": "Debit",
            "dr": "Debit",
            "credit amount": "Credit",
            "cr amount": "Credit",
            "credit": "Credit",
            "cr": "Credit",
            "running balance": "Balance",
            "closing balance": "Balance",
            "balance": "Balance",
        }

        df = df.rename(
            columns=lambda c: column_mapping.get(str(c).lower().strip(), c)
        )

        for col in self.required_columns:
            if col not in df.columns:
                df[col] = ""

        return df[self.required_columns]

    def _validate_and_clean(self, df: pd.DataFrame) -> pd.DataFrame:
        """Final cleaning: drop invalid rows, fix types"""
        if df.empty:
            return pd.DataFrame(columns=self.required_columns)

        cleaned = []
        for _, row in df.iterrows():
            txn = row.to_dict()
            if self._is_valid_transaction(txn):
                cleaned.append(txn)

        df = pd.DataFrame(cleaned)

        # Normalize dates
        for fmt in ["%d/%m/%Y", "%d-%m-%Y", "%d %b %Y", "%d/%m/%y"]:
            try:
                df["Date"] = pd.to_datetime(df["Date"], format=fmt, errors="coerce")
            except Exception:
                pass

        df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
        df = df.dropna(subset=["Date"])

        # Normalize amounts
        for col in ["Debit", "Credit", "Balance"]:
            df[col] = (
                df[col].astype(str)
                .str.replace(",", "", regex=False)
                .replace("", np.nan)
                .astype(float, errors="ignore")
            )

        return df.reset_index(drop=True)
